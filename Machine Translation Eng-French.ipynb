{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077821ea-2f46-435f-9478-517a75d82705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee8d8c-3731-4c0e-ba5b-738df348fe86",
   "metadata": {},
   "source": [
    "!pip install --ignore-installed --user --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3b14cc-c118-431c-90c9-d5db2ee9ff10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c79fde-7745-403b-90a8-828d6b3e0c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a GPU with the name: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(\"Found a GPU with the name:\", gpu.name)\n",
    "else:\n",
    "    print(\"Failed to detect a GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b347c4f-c2ed-421e-8714-a5425c428905",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(r\"data/fra.txt\", delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f09b5bd2-d214-40ad-9cf9-7e48b01c849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bfa128c-f4f8-4445-ae95-2fc7327233ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Marche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>En route !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Bouge !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0           1\n",
       "0  Go.        Va !\n",
       "1  Go.     Marche.\n",
       "2  Go.  En route !\n",
       "3  Go.     Bouge !\n",
       "4  Hi.     Salut !"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0086259f-7442-4b82-b0a1-4c2ff1f52003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229803, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13558451-8566-4fd6-8b8f-181256c45c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns= {0:'English', 1:'French'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa5d6db6-83fb-4a66-8ca6-f35df0caa684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Marche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>En route !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Bouge !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English      French\n",
       "0     Go.        Va !\n",
       "1     Go.     Marche.\n",
       "2     Go.  En route !\n",
       "3     Go.     Bouge !\n",
       "4     Hi.     Salut !"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45bed880-5cbf-48fe-b819-bc58ec317e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['English']= data['English'].astype(str)\n",
    "data['French']= data['French'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbe7977c-a69c-4fbc-a525-45849c209605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 229803 entries, 0 to 229802\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   English  229803 non-null  object\n",
      " 1   French   229803 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99f42ba4-22ec-4918-bb3b-0343f251a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "def clean_string(string):\n",
    "    # Replace no-break space with space\n",
    "    string = string.replace(\"\\u202f\",\" \")\n",
    "    # Converts all uppercase characters into lowercase characters\n",
    "    string = string.lower()\n",
    "\n",
    "    # Delete the punctuation and the numbers\n",
    "    for p in punctuation + \"«»\" + \"0123456789\":\n",
    "        string = string.replace(p,\" \")\n",
    "\n",
    "    # Eliminate duplicate whitespaces using wildcards\n",
    "    string = re.sub(\"\\s+\",\" \", string)\n",
    "    # Remove spaces at the beginning and at the end of the string\n",
    "    string = string.strip()\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ea5f68-0ef5-48cc-9265-2344fda220ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['English'] = data['English'].apply(lambda x: clean_string(x))\n",
    "data['French'] = data['French'].apply(lambda x: clean_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "773d8ba9-7cdd-495d-be04-97a22975c712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data= data.iloc[:15000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06429fb3-2c39-467a-8916-c8f8694ab7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229803, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b2e6bd-c3e1-48df-849c-2d942752b556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>marche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>go</td>\n",
       "      <td>en route</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>go</td>\n",
       "      <td>bouge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi</td>\n",
       "      <td>salut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English    French\n",
       "0      go        va\n",
       "1      go    marche\n",
       "2      go  en route\n",
       "3      go     bouge\n",
       "4      hi     salut"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfcc6ac6-5e51-472d-b397-a9bf8b74ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentences= data['English'].values\n",
    "target_sentences= data['French'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2f56069-1ca9-46f5-836d-94d01c3f03cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22980"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_split= int(source_sentences.shape[0] * 0.1 )\n",
    "train_data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed0d24fa-873e-4a68-bc06-bb7e5cff0157",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentences, source_val_sentences= source_sentences[train_data_split:], source_sentences[:train_data_split]\n",
    "target_sentences, target_val_sentences= target_sentences[train_data_split:], target_sentences[:train_data_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6bc5e55-f265-4e32-88ba-462e07044129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_target_sentences(sentences):\n",
    "  tagged_sentences = map(lambda s: (' ').join(['<sos>', s, '<eos>']), sentences)\n",
    "  return list(tagged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67cbabcd-8723-4fb7-bd30-83c6ce5f3fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sentences= tag_target_sentences(target_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26078fcb-36d9-47ce-bc00-a062e3569450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> ils sont artistes <eos>',\n",
       " '<sos> elles sont artistes <eos>',\n",
       " '<sos> ils sont médecins <eos>',\n",
       " '<sos> elles sont médecins <eos>',\n",
       " '<sos> ils sont chanteurs <eos>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb8ae3de-e83e-4121-a7cc-81e9896ce6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206823"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aab77cf-f57d-4080-a8c9-9ea3aeb45b42",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e50629d-4327-4f2a-beba-ea0778a2581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE Tokenization\n",
    "source_tokenizer= tf.keras.preprocessing.text.Tokenizer(oov_token=\"<unk>\", filters=\"#$%&()*+,-./:;=@[\\\\]^_`{|}~\\t\\n\")\n",
    "source_tokenizer.fit_on_texts(source_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45c8e854-d5a8-4012-a1aa-98f20723bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoder_inputs = source_tokenizer.texts_to_sequences(source_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e3e44f5-346d-4590-b924-82f09ada01a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15639"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_vocab_size= len(source_tokenizer.word_index) + 1\n",
    "source_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76cc1f39-1a0a-4a16-841e-a06f80ba17d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43, 58, 510], [43, 58, 626], [43, 58, 626], [43, 58, 626], [43, 58, 626]]\n",
      "['they were hungry', 'they were killed', 'they were killed', 'they were killed', 'they were killed']\n"
     ]
    }
   ],
   "source": [
    "print(train_encoder_inputs[60:65])\n",
    "print(source_tokenizer.sequences_to_texts(train_encoder_inputs[60:65]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5dde77ba-6d45-422d-94ef-2c1c513a21eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET Tokenization\n",
    "target_tokenizer= tf.keras.preprocessing.text.Tokenizer(oov_token=\"<unk>\", filters=\"#$%&()*+,-./:;=@[\\\\]^_`{|}~\\t\\n\")\n",
    "target_tokenizer.fit_on_texts(target_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "819434e8-ad88-4832-a8fe-a533b9628b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26368"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vocab_size= len(target_tokenizer.word_index) + 1\n",
    "target_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95bfd0d9-0479-4f34-97ec-2d7d22fa058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_decoder_inputs_targets(sequences, tokenizer):\n",
    "    seqs= tokenizer.texts_to_sequences(sequences)\n",
    "    decoder_inputs= [s[:-1] for s in seqs] # Drops last token in sequence; eg = <sos> Hi I am Arvind\n",
    "    decoder_outputs= [s[1:] for s in seqs] # Drops first token in sequence; eg = Hi I am Arvind <eos>\n",
    "\n",
    "    return decoder_inputs, decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aaecf90d-f18f-47af-86d0-e2a963caf165",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_decoder_inputs, train_decoder_outputs= generate_decoder_inputs_targets(target_sentences, target_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cea2629-d600-44ea-b2f0-c171c6edbe51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> ils sont artistes',\n",
       " '<sos> elles sont artistes',\n",
       " '<sos> ils sont médecins',\n",
       " '<sos> elles sont médecins',\n",
       " '<sos> ils sont chanteurs']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decoder inputs \n",
    "target_tokenizer.sequences_to_texts(train_decoder_inputs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cb9ebb5-6022-47d8-a7a5-80cb008755f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ils sont artistes <eos>',\n",
       " 'elles sont artistes <eos>',\n",
       " 'ils sont médecins <eos>',\n",
       " 'elles sont médecins <eos>',\n",
       " 'ils sont chanteurs <eos>']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decoder outputs\n",
    "target_tokenizer.sequences_to_texts(train_decoder_outputs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a57c965-3372-4537-83d6-a0004c7d973c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_encoding_len= len(max(train_encoder_inputs, key= len))\n",
    "max_encoding_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22536604-06f3-429e-bbd7-8655b0d75f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_decoding_len= len(max(train_decoder_inputs, key= len))\n",
    "max_decoding_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044030cb-e00a-4a3f-9584-d86f041f7177",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "957abfc6-af6a-4274-9d31-26b098dce537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_train_encoder_inputs= pad_sequences(train_encoder_inputs, maxlen= max_encoding_len, padding= \"post\", truncating= \"post\")\n",
    "padded_train_decoder_inputs= pad_sequences(train_decoder_inputs, maxlen= max_decoding_len, padding= \"post\", truncating= \"post\")\n",
    "padded_train_decoder_outputs= pad_sequences(train_decoder_outputs, maxlen= max_decoding_len, padding= \"post\", truncating= \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d57a293-33c0-4cc3-bd90-913368f73daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  43 3325   93    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "[   2  110   24   92 7086    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "[ 110   24   92 7086    3    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(padded_train_encoder_inputs[10])\n",
    "print(padded_train_decoder_inputs[10])\n",
    "print(padded_train_decoder_outputs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0783f28d-e83c-4943-a5e5-382e7571084b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it s a pleasure to be here <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 is considered as OOV and given <unk> value\n",
    "source_tokenizer.sequences_to_texts([padded_train_encoder_inputs[80000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f9506-06c0-4abc-8746-97c55b319496",
   "metadata": {},
   "source": [
    "### validation data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "425354ff-c555-4692-b86b-d21f2ddae3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(preprocessed_input, preprocessed_output):\n",
    "    \n",
    "    tagged_preprocessed_output = tag_target_sentences(preprocessed_output)\n",
    "    # Vectorize encoder source sentences.\n",
    "    encoder_inputs = source_tokenizer.texts_to_sequences(preprocessed_input)\n",
    "    # Vectorize and create decoder input and target sentences.\n",
    "    decoder_inputs, decoder_targets = generate_decoder_inputs_targets(tagged_preprocessed_output, \n",
    "                                                                    target_tokenizer)\n",
    "  \n",
    "    # Pad all collections.\n",
    "    padded_encoder_inputs = pad_sequences(encoder_inputs, max_encoding_len, padding='post', truncating='post')\n",
    "    padded_decoder_inputs = pad_sequences(decoder_inputs, max_decoding_len, padding='post', truncating='post')\n",
    "    padded_decoder_targets = pad_sequences(decoder_targets, max_decoding_len, padding='post', truncating='post')\n",
    "\n",
    "    return padded_encoder_inputs, padded_decoder_inputs, padded_decoder_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b8488bf-1d32-409f-ac30-0c3aa9b18b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process validation dataset\n",
    "padded_val_encoder_inputs, padded_val_decoder_inputs, padded_val_decoder_targets= process_dataset(source_val_sentences, target_val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bdd1e5b-a2e6-40be-8252-f23d505ed791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> soyez satisfait <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tokenizer.sequences_to_texts([padded_val_decoder_inputs[1780]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e8e09-4e23-48eb-9fcc-953fcf2896ab",
   "metadata": {},
   "source": [
    "### Building Translation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17de62d8-8af4-421f-a381-9fd1db8567e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim= 128\n",
    "hidden_dim= 256\n",
    "default_dropout= 0.2\n",
    "batch_size= 32\n",
    "epochs= 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66b0b22e-5fda-45d0-9967-c5e2a2fda541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "\n",
    "encoder_inputs= Input(shape= [None], name= 'encoder_inputs')\n",
    "#  mask_zero: Boolean, whether or not the input value 0 is a special\n",
    "encoder_embeddings= Embedding(input_dim= source_vocab_size, output_dim= embedding_dim, mask_zero= True, name= \"encoder_embeddings\")\n",
    "encoder_embedding_outputs= encoder_embeddings(encoder_inputs)\n",
    "\n",
    "encoder_lstm= LSTM(units= hidden_dim, return_state= True, dropout= default_dropout, name= \"encoder_lstm\")\n",
    "# since return sequences is false: the value of encoder_outputs is same as state_h, \n",
    "# if true, all y_hat values of every time stamp is returned to encoder_outputs\n",
    "encoder_outputs, state_h, state_c= encoder_lstm(encoder_embedding_outputs)\n",
    "\n",
    "encoder_states= (state_h, state_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c30b3ad-2b8c-45a2-b1bf-7f2d4e722078",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs= Input(shape= [None], name= \"decoder_inputs\")\n",
    "decoder_embeddings= Embedding(input_dim= target_vocab_size, output_dim= embedding_dim, mask_zero= True, name= \"decoder_embeddings\")\n",
    "decoder_embedding_outputs= decoder_embeddings(decoder_inputs)\n",
    "\n",
    "decoder_lstm= LSTM(units= hidden_dim, return_sequences=True ,return_state= True, dropout= default_dropout, name= \"decoder_lstm\")\n",
    "\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_embedding_outputs, initial_state= encoder_states)\n",
    "\n",
    "decoder_dense= Dense(target_vocab_size, activation='softmax', name=\"decoder_dense\")\n",
    "\n",
    "y_proba= decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01947580-48d4-4d2b-a415-f8ef162085d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"eng_fre_seq2seq_nmt_no_attention\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " encoder_embeddings (Embedding)  (None, None, 128)   2001792     ['encoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " decoder_embeddings (Embedding)  (None, None, 128)   3375104     ['decoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 256),        394240      ['encoder_embeddings[0][0]']     \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            [(None, None, 256),  394240      ['decoder_embeddings[0][0]',     \n",
      "                                 (None, 256),                     'encoder_lstm[0][1]',           \n",
      "                                 (None, 256)]                     'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " decoder_dense (Dense)          (None, None, 26368)  6776576     ['decoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,941,952\n",
      "Trainable params: 12,941,952\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Note how the model is taking two inputs in an array.\n",
    "model = tf.keras.Model([encoder_inputs, decoder_inputs], y_proba, name='eng_fre_seq2seq_nmt_no_attention')\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "516c9212-f288-408c-b7b3-1ddb776bb939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='eng_fre_seq2seq_nmt_no_attention.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48963087-a389-46b1-8fc0-d988ecbe33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving this to a folder on my local machine.\n",
    "filepath=\"./EngFreNMTNoAttention/training1/cp.ckpt\"\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a2756954-f4f1-4511-afad-e20df50abc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6463/6464 [============================>.] - ETA: 0s - loss: 0.1900 - accuracy: 0.6730\n",
      "Epoch 1: saving model to ./EngFreNMTNoAttention/training1\\cp.ckpt\n",
      "6464/6464 [==============================] - 679s 105ms/step - loss: 0.1900 - accuracy: 0.6730 - val_loss: 0.1294 - val_accuracy: 0.6882\n",
      "Epoch 2/30\n",
      "6463/6464 [============================>.] - ETA: 0s - loss: 0.1643 - accuracy: 0.7037\n",
      "Epoch 2: saving model to ./EngFreNMTNoAttention/training1\\cp.ckpt\n",
      "6464/6464 [==============================] - 679s 105ms/step - loss: 0.1643 - accuracy: 0.7037 - val_loss: 0.1253 - val_accuracy: 0.6951\n",
      "Epoch 3/30\n",
      "6463/6464 [============================>.] - ETA: 0s - loss: 0.1466 - accuracy: 0.7258\n",
      "Epoch 3: saving model to ./EngFreNMTNoAttention/training1\\cp.ckpt\n",
      "6464/6464 [==============================] - 678s 105ms/step - loss: 0.1466 - accuracy: 0.7258 - val_loss: 0.1232 - val_accuracy: 0.7001\n",
      "Epoch 4/30\n",
      "6463/6464 [============================>.] - ETA: 0s - loss: 0.1335 - accuracy: 0.7430\n",
      "Epoch 4: saving model to ./EngFreNMTNoAttention/training1\\cp.ckpt\n",
      "6464/6464 [==============================] - 682s 106ms/step - loss: 0.1335 - accuracy: 0.7430 - val_loss: 0.1222 - val_accuracy: 0.7023\n",
      "Epoch 5/30\n",
      "6464/6464 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.7567\n",
      "Epoch 5: saving model to ./EngFreNMTNoAttention/training1\\cp.ckpt\n",
      "6464/6464 [==============================] - 678s 105ms/step - loss: 0.1236 - accuracy: 0.7567 - val_loss: 0.1219 - val_accuracy: 0.7050\n",
      "Epoch 6/30\n",
      "6463/6464 [============================>.] - ETA: 0s - loss: 0.1158 - accuracy: 0.7685\n",
      "Epoch 6: saving model to ./EngFreNMTNoAttention/training1\\cp.ckpt\n",
      "6464/6464 [==============================] - 681s 105ms/step - loss: 0.1158 - accuracy: 0.7685 - val_loss: 0.1215 - val_accuracy: 0.7069\n",
      "Epoch 7/30\n",
      "6464/6464 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.7783\n",
      "Epoch 7: saving model to ./EngFreNMTNoAttention/training1\\cp.ckpt\n",
      "6464/6464 [==============================] - 682s 106ms/step - loss: 0.1094 - accuracy: 0.7783 - val_loss: 0.1218 - val_accuracy: 0.7082\n",
      "Epoch 8/30\n",
      "1387/6464 [=====>........................] - ETA: 8:19 - loss: 0.0984 - accuracy: 0.7979"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m es_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpadded_train_encoder_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadded_train_decoder_inputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadded_train_decoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpadded_val_encoder_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadded_val_decoder_inputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadded_val_decoder_targets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mes_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU-ENV\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU-ENV\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU-ENV\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU-ENV\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU-ENV\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU-ENV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU-ENV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU-ENV\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU-ENV\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model.fit([padded_train_encoder_inputs, padded_train_decoder_inputs], padded_train_decoder_outputs,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=epochs,\n",
    "                     validation_data=([padded_val_encoder_inputs, padded_val_decoder_inputs], padded_val_decoder_targets),\n",
    "                     callbacks=[cp_callback, es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ece6e457-d2e8-41ad-8345-5142316c7866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x18cf55e4820>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Reconstruct the model architecture\n",
    "model = tf.keras.Model([encoder_inputs, decoder_inputs], y_proba, name='eng_fre_seq2seq_nmt_no_attention') # Define a function or code snippet to create your model architecture\n",
    "\n",
    "# Compile the model (if needed)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Load the weights from the checkpoint file\n",
    "model.load_weights(filepath=\"./EngFreNMTNoAttention/training1/cp.ckpt\")\n",
    "\n",
    "# Now the model is loaded with the weights from the checkpoint file and ready for inference or further training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4989b073-153b-4047-9df5-2ce4940e0cc6",
   "metadata": {},
   "source": [
    "### Saving Model and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "210d6c4e-c702-4ce9-b397-82e87582ac05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Saving Model\n",
    "from keras.models import load_model\n",
    "\n",
    "# Save model to HDF5 format\n",
    "model.save('artifacts/Eng-French/eng_fre_seq2seq_nmt_no_attention.h5')\n",
    "\n",
    "# Load model from HDF5 format\n",
    "loaded_model = load_model('artifacts/Eng-French/eng_fre_seq2seq_nmt_no_attention.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc1d5d1a-390b-467c-81a1-1ba41ea04fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model.fit([padded_train_encoder_inputs, padded_train_decoder_inputs], padded_train_decoder_outputs,\n",
    "#                      batch_size=batch_size,\n",
    "#                      epochs=3,\n",
    "#                      validation_data=([padded_val_encoder_inputs, padded_val_decoder_inputs], padded_val_decoder_targets),\n",
    "#                      callbacks=[cp_callback, es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b6f965f0-8380-4701-b2e1-ad7fd45ebb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Tokenizer\n",
    "import io\n",
    "import json\n",
    "\n",
    "\n",
    "##### Save the tokenizers as JSON files. The resulting files can be downloaded by left-clicking on them.\n",
    "source_tokenizer_json = source_tokenizer.to_json()\n",
    "with io.open('artifacts/Eng-French/source_tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "  f.write(json.dumps(source_tokenizer_json, ensure_ascii=False))\n",
    "\n",
    "target_tokenizer_json = target_tokenizer.to_json()\n",
    "with io.open('artifacts/Eng-French/target_tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "  f.write(json.dumps(target_tokenizer_json, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "427b272c-fb78-4ea6-90cc-4ba084296399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Tokenizer\n",
    "with io.open('artifacts/Eng-French/source_tokenizer.json', 'r', encoding='utf-8') as f:\n",
    "    # Read the JSON data\n",
    "    st= json.load(f)\n",
    "    st = tf.keras.preprocessing.text.tokenizer_from_json(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b79389-e5b6-4dc2-a3ca-da0213256c38",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f1406c72-3c32-44b0-8029-024421c8d314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719/719 [==============================] - 45s 59ms/step - loss: 0.1219 - accuracy: 0.7072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12190192937850952, 0.7072119116783142]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test set.\n",
    "model.evaluate([padded_val_encoder_inputs, padded_val_decoder_inputs], padded_val_decoder_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92d1a289-5edc-4b7b-8b5f-8aa373e51e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder_inputs',\n",
       " 'decoder_inputs',\n",
       " 'encoder_embeddings',\n",
       " 'decoder_embeddings',\n",
       " 'encoder_lstm',\n",
       " 'decoder_lstm',\n",
       " 'decoder_dense']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[layer.name for layer in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5af5c2b0-e63f-4eac-816f-b823c76de1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = model.get_layer('encoder_inputs').input\n",
    "\n",
    "encoder_embedding_layer = model.get_layer('encoder_embeddings')\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "encoder_lstm = model.get_layer('encoder_lstm')\n",
    "\n",
    "_, encoder_state_h, encoder_state_c = encoder_lstm(encoder_embeddings)\n",
    "\n",
    "encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "encoder_model_no_attention = tf.keras.Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3c395b2d-7038-461f-944b-c3a824c5c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = model.get_layer('decoder_inputs').input\n",
    "\n",
    "decoder_embedding_layer = model.get_layer('decoder_embeddings')\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# Inputs to represent the decoder's LSTM hidden and cell states. We'll populate \n",
    "# these manually using the encoder's output for the initial state.\n",
    "decoder_input_state_h = tf.keras.Input(shape=(hidden_dim,), name='decoder_input_state_h')\n",
    "decoder_input_state_c = tf.keras.Input(shape=(hidden_dim,), name='decoder_input_state_c')\n",
    "decoder_input_states = [decoder_input_state_h, decoder_input_state_c]\n",
    "\n",
    "decoder_lstm = model.get_layer('decoder_lstm')\n",
    "\n",
    "decoder_sequence_outputs, decoder_output_state_h, decoder_output_state_c = decoder_lstm(\n",
    "    decoder_embeddings, initial_state=decoder_input_states\n",
    ")\n",
    "\n",
    "# Update hidden and cell states for the next time step.\n",
    "decoder_output_states = [decoder_output_state_h, decoder_output_state_c]\n",
    "\n",
    "decoder_dense = model.get_layer('decoder_dense')\n",
    "y_proba = decoder_dense(decoder_sequence_outputs)\n",
    "\n",
    "decoder_model_no_attention = tf.keras.Model(\n",
    "    [decoder_inputs] + decoder_input_states, \n",
    "    [y_proba] + decoder_output_states\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0a4c39fa-3d3d-417a-8819-e04bf02706ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_without_attention(sentence: str, \n",
    "                                source_tokenizer, encoder,\n",
    "                                target_tokenizer, decoder,\n",
    "                                max_translated_len = 30):\n",
    "\n",
    "  # Vectorize the source sentence and run it through the encoder.    \n",
    "  input_seq = source_tokenizer.texts_to_sequences([sentence])\n",
    "\n",
    "  # Get the tokenized sentence to see if there are any unknown tokens.\n",
    "  tokenized_sentence = source_tokenizer.sequences_to_texts(input_seq)\n",
    "\n",
    "  states = encoder.predict(input_seq)  \n",
    "\n",
    "  current_word = '<sos>'\n",
    "  decoded_sentence = []\n",
    "\n",
    "  while len(decoded_sentence) < max_translated_len:\n",
    "    \n",
    "    # Set the next input word for the decoder.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = target_tokenizer.word_index[current_word]\n",
    "    \n",
    "    # Determine the next word.\n",
    "    target_y_proba, h, c = decoder.predict([target_seq] + states)\n",
    "    target_token_index = np.argmax(target_y_proba[0, -1, :])\n",
    "    current_word = target_tokenizer.index_word[target_token_index]\n",
    "\n",
    "    if (current_word == '<eos>'):\n",
    "      break\n",
    "\n",
    "    decoded_sentence.append(current_word)\n",
    "    states = [h, c]\n",
    "  \n",
    "  return tokenized_sentence[0], ' '.join(decoded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "33c842a9-9aef-40e3-a30b-09ba2dd32e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "source_sentences= source_val_sentences[600:650]\n",
    "target_sentences= target_val_sentences[600:650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "294c253d-6d43-4ca2-80a0-ba1c73cfefdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentences(source_sentences, target_sentences,translation_func, source_tokenizer, encoder,\n",
    "                        target_tokenizer, decoder):\n",
    "  translations = {'Tokenized Original': [], 'Reference': [], 'Translation': []}\n",
    "\n",
    "  for s in source_sentences:\n",
    "    tokenized_sentence, translated = translation_func(s, source_tokenizer, encoder,\n",
    "                                                      target_tokenizer, decoder)\n",
    "\n",
    "    translations['Tokenized Original'].append(tokenized_sentence)\n",
    "    translations['Translation'].append(translated)\n",
    "\n",
    "  for t in target_sentences:\n",
    "      translations['Reference'].append(t)\n",
    "  \n",
    "  return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "82646ab9-3024-49d3-88ba-ef64a9562a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('<unk>', 'à l air')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_without_attention([\"he spoke\"], source_tokenizer, encoder_model_no_attention, target_tokenizer, decoder_model_no_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "03cd9531-d70e-4171-ba0d-1fd6b80a0d92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokenized Original</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good job</td>\n",
       "      <td>beau travail</td>\n",
       "      <td>bon travail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good job</td>\n",
       "      <td>bravo</td>\n",
       "      <td>bon travail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grab tom</td>\n",
       "      <td>attrape tom</td>\n",
       "      <td>emmène tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grab tom</td>\n",
       "      <td>attrapez tom</td>\n",
       "      <td>emmène tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grab him</td>\n",
       "      <td>attrape le</td>\n",
       "      <td>lui le prenez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grab him</td>\n",
       "      <td>attrapez le</td>\n",
       "      <td>lui le prenez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grab him</td>\n",
       "      <td>mettez lui la main dessus</td>\n",
       "      <td>lui le prenez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>have fun</td>\n",
       "      <td>amuse toi bien</td>\n",
       "      <td>vous amusez bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>have fun</td>\n",
       "      <td>amusez vous bien</td>\n",
       "      <td>vous amusez bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>have fun</td>\n",
       "      <td>amuse toi bien</td>\n",
       "      <td>vous amusez bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>have fun</td>\n",
       "      <td>amusez vous bien</td>\n",
       "      <td>vous amusez bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>he spoke</td>\n",
       "      <td>il a parlé</td>\n",
       "      <td>il a parlé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>he spoke</td>\n",
       "      <td>il a pris la parole</td>\n",
       "      <td>il a parlé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>he spoke</td>\n",
       "      <td>il s est exprimé</td>\n",
       "      <td>il a parlé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>he tries</td>\n",
       "      <td>il essaye</td>\n",
       "      <td>il reste en effet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>he s wet</td>\n",
       "      <td>il est mouillé</td>\n",
       "      <td>il est mouillé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>help tom</td>\n",
       "      <td>aide tom</td>\n",
       "      <td>tom a besoin de tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>help tom</td>\n",
       "      <td>aidez tom</td>\n",
       "      <td>tom a besoin de tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>help tom</td>\n",
       "      <td>aidez tom</td>\n",
       "      <td>tom a besoin de tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hi guys</td>\n",
       "      <td>salut les mecs</td>\n",
       "      <td>salut les mecs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>how cute</td>\n",
       "      <td>comme c est mignon</td>\n",
       "      <td>de quoi que ce soit mignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>how cute</td>\n",
       "      <td>trop mignon</td>\n",
       "      <td>de quoi que ce soit mignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>how cute</td>\n",
       "      <td>trop mignonne</td>\n",
       "      <td>de quoi que ce soit mignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>how deep</td>\n",
       "      <td>quelle profondeur</td>\n",
       "      <td>quelle déception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>how nice</td>\n",
       "      <td>comme elle est belle</td>\n",
       "      <td>quelle belle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>how nice</td>\n",
       "      <td>comme c est chouette</td>\n",
       "      <td>quelle belle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>how nice</td>\n",
       "      <td>comme c est gentil</td>\n",
       "      <td>quelle belle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>how nice</td>\n",
       "      <td>c est du joli</td>\n",
       "      <td>quelle belle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>how nice</td>\n",
       "      <td>comme c est agréable</td>\n",
       "      <td>quelle belle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>how rude</td>\n",
       "      <td>quelle grossièreté</td>\n",
       "      <td>comment s est déroulé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>how wise</td>\n",
       "      <td>quelle sagesse</td>\n",
       "      <td>comment faire de ton mieux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>hurry up</td>\n",
       "      <td>dépêche toi</td>\n",
       "      <td>dépêche toi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>hurry up</td>\n",
       "      <td>grouille</td>\n",
       "      <td>dépêche toi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>hurry up</td>\n",
       "      <td>pressez vous</td>\n",
       "      <td>dépêche toi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>hurry up</td>\n",
       "      <td>fiça</td>\n",
       "      <td>dépêche toi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>hurry up</td>\n",
       "      <td>magne toi</td>\n",
       "      <td>dépêche toi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>hurry up</td>\n",
       "      <td>magnez vous</td>\n",
       "      <td>dépêche toi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>i am tom</td>\n",
       "      <td>je suis tom</td>\n",
       "      <td>je suis tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>i cursed</td>\n",
       "      <td>j ai juré</td>\n",
       "      <td>je suis désolé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>i did ok</td>\n",
       "      <td>je m en suis bien sorti</td>\n",
       "      <td>j ai fait preuve de main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>i did ok</td>\n",
       "      <td>je m en suis bien sortie</td>\n",
       "      <td>j ai fait preuve de main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>i did it</td>\n",
       "      <td>je l ai fait</td>\n",
       "      <td>je l ai fait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>i did it</td>\n",
       "      <td>c est moi qui l ai fait</td>\n",
       "      <td>je l ai fait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>i failed</td>\n",
       "      <td>j ai échoué</td>\n",
       "      <td>j ai échoué</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>i forgot</td>\n",
       "      <td>j ai oublié</td>\n",
       "      <td>j ai oublié</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>i get it</td>\n",
       "      <td>j ai compris</td>\n",
       "      <td>je l ai remis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>i &lt;unk&gt;</td>\n",
       "      <td>j ai fait une gaffe</td>\n",
       "      <td>je suis en train de me faire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>i got it</td>\n",
       "      <td>j ai compris</td>\n",
       "      <td>je l ai eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>i got it</td>\n",
       "      <td>j ai capté</td>\n",
       "      <td>je l ai eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>i helped</td>\n",
       "      <td>j ai aidé</td>\n",
       "      <td>j ai aidé</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tokenized Original                  Reference                   Translation\n",
       "0            good job               beau travail                   bon travail\n",
       "1            good job                      bravo                   bon travail\n",
       "2            grab tom                attrape tom                    emmène tom\n",
       "3            grab tom               attrapez tom                    emmène tom\n",
       "4            grab him                 attrape le                 lui le prenez\n",
       "5            grab him                attrapez le                 lui le prenez\n",
       "6            grab him  mettez lui la main dessus                 lui le prenez\n",
       "7            have fun             amuse toi bien              vous amusez bien\n",
       "8            have fun           amusez vous bien              vous amusez bien\n",
       "9            have fun             amuse toi bien              vous amusez bien\n",
       "10           have fun           amusez vous bien              vous amusez bien\n",
       "11           he spoke                 il a parlé                    il a parlé\n",
       "12           he spoke        il a pris la parole                    il a parlé\n",
       "13           he spoke           il s est exprimé                    il a parlé\n",
       "14           he tries                  il essaye             il reste en effet\n",
       "15           he s wet             il est mouillé                il est mouillé\n",
       "16           help tom                   aide tom           tom a besoin de tom\n",
       "17           help tom                  aidez tom           tom a besoin de tom\n",
       "18           help tom                  aidez tom           tom a besoin de tom\n",
       "19            hi guys             salut les mecs                salut les mecs\n",
       "20           how cute         comme c est mignon    de quoi que ce soit mignon\n",
       "21           how cute                trop mignon    de quoi que ce soit mignon\n",
       "22           how cute              trop mignonne    de quoi que ce soit mignon\n",
       "23           how deep          quelle profondeur              quelle déception\n",
       "24           how nice       comme elle est belle                  quelle belle\n",
       "25           how nice       comme c est chouette                  quelle belle\n",
       "26           how nice         comme c est gentil                  quelle belle\n",
       "27           how nice              c est du joli                  quelle belle\n",
       "28           how nice       comme c est agréable                  quelle belle\n",
       "29           how rude         quelle grossièreté         comment s est déroulé\n",
       "30           how wise             quelle sagesse    comment faire de ton mieux\n",
       "31           hurry up                dépêche toi                   dépêche toi\n",
       "32           hurry up                   grouille                   dépêche toi\n",
       "33           hurry up               pressez vous                   dépêche toi\n",
       "34           hurry up                       fiça                   dépêche toi\n",
       "35           hurry up                  magne toi                   dépêche toi\n",
       "36           hurry up                magnez vous                   dépêche toi\n",
       "37           i am tom                je suis tom                   je suis tom\n",
       "38           i cursed                  j ai juré                je suis désolé\n",
       "39           i did ok    je m en suis bien sorti      j ai fait preuve de main\n",
       "40           i did ok   je m en suis bien sortie      j ai fait preuve de main\n",
       "41           i did it               je l ai fait                  je l ai fait\n",
       "42           i did it    c est moi qui l ai fait                  je l ai fait\n",
       "43           i failed                j ai échoué                   j ai échoué\n",
       "44           i forgot                j ai oublié                   j ai oublié\n",
       "45           i get it               j ai compris                 je l ai remis\n",
       "46            i <unk>        j ai fait une gaffe  je suis en train de me faire\n",
       "47           i got it               j ai compris                    je l ai eu\n",
       "48           i got it                 j ai capté                    je l ai eu\n",
       "49           i helped                  j ai aidé                     j ai aidé"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations_no_attention = pd.DataFrame(translate_sentences(source_sentences, target_sentences, translate_without_attention,\n",
    "                                                             source_tokenizer, encoder_model_no_attention,\n",
    "                                                             target_tokenizer, decoder_model_no_attention))\n",
    "translations_no_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "87b0ab51-e9e3-4b52-8991-d7bb93e653a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokenized Original</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good job</td>\n",
       "      <td>beau travail</td>\n",
       "      <td>bon travail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good job</td>\n",
       "      <td>bravo</td>\n",
       "      <td>bon travail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grab tom</td>\n",
       "      <td>attrape tom</td>\n",
       "      <td>emmène tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grab tom</td>\n",
       "      <td>attrapez tom</td>\n",
       "      <td>emmène tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grab him</td>\n",
       "      <td>attrape le</td>\n",
       "      <td>lui le prenez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grab him</td>\n",
       "      <td>attrapez le</td>\n",
       "      <td>lui le prenez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grab him</td>\n",
       "      <td>mettez lui la main dessus</td>\n",
       "      <td>lui le prenez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>have fun</td>\n",
       "      <td>amuse toi bien</td>\n",
       "      <td>vous amusez bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>have fun</td>\n",
       "      <td>amusez vous bien</td>\n",
       "      <td>vous amusez bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>have fun</td>\n",
       "      <td>amuse toi bien</td>\n",
       "      <td>vous amusez bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>have fun</td>\n",
       "      <td>amusez vous bien</td>\n",
       "      <td>vous amusez bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>he spoke</td>\n",
       "      <td>il a parlé</td>\n",
       "      <td>il a parlé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>he spoke</td>\n",
       "      <td>il a pris la parole</td>\n",
       "      <td>il a parlé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>he spoke</td>\n",
       "      <td>il s est exprimé</td>\n",
       "      <td>il a parlé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>he tries</td>\n",
       "      <td>il essaye</td>\n",
       "      <td>il reste en effet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>he s wet</td>\n",
       "      <td>il est mouillé</td>\n",
       "      <td>il est mouillé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>help tom</td>\n",
       "      <td>aide tom</td>\n",
       "      <td>tom a besoin de tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>help tom</td>\n",
       "      <td>aidez tom</td>\n",
       "      <td>tom a besoin de tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>help tom</td>\n",
       "      <td>aidez tom</td>\n",
       "      <td>tom a besoin de tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hi guys</td>\n",
       "      <td>salut les mecs</td>\n",
       "      <td>salut les mecs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>how cute</td>\n",
       "      <td>comme c est mignon</td>\n",
       "      <td>de quoi que ce soit mignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>how cute</td>\n",
       "      <td>trop mignon</td>\n",
       "      <td>de quoi que ce soit mignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>how cute</td>\n",
       "      <td>trop mignonne</td>\n",
       "      <td>de quoi que ce soit mignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>how deep</td>\n",
       "      <td>quelle profondeur</td>\n",
       "      <td>quelle déception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>how nice</td>\n",
       "      <td>comme elle est belle</td>\n",
       "      <td>quelle belle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>how nice</td>\n",
       "      <td>comme c est chouette</td>\n",
       "      <td>quelle belle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>how nice</td>\n",
       "      <td>comme c est gentil</td>\n",
       "      <td>quelle belle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>how nice</td>\n",
       "      <td>c est du joli</td>\n",
       "      <td>quelle belle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>how nice</td>\n",
       "      <td>comme c est agréable</td>\n",
       "      <td>quelle belle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>how rude</td>\n",
       "      <td>quelle grossièreté</td>\n",
       "      <td>comment s est déroulé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>how wise</td>\n",
       "      <td>quelle sagesse</td>\n",
       "      <td>comment faire de ton mieux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>hurry up</td>\n",
       "      <td>dépêche toi</td>\n",
       "      <td>dépêche toi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>hurry up</td>\n",
       "      <td>grouille</td>\n",
       "      <td>dépêche toi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>hurry up</td>\n",
       "      <td>pressez vous</td>\n",
       "      <td>dépêche toi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>hurry up</td>\n",
       "      <td>fiça</td>\n",
       "      <td>dépêche toi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>hurry up</td>\n",
       "      <td>magne toi</td>\n",
       "      <td>dépêche toi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>hurry up</td>\n",
       "      <td>magnez vous</td>\n",
       "      <td>dépêche toi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>i am tom</td>\n",
       "      <td>je suis tom</td>\n",
       "      <td>je suis tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>i cursed</td>\n",
       "      <td>j ai juré</td>\n",
       "      <td>je suis désolé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>i did ok</td>\n",
       "      <td>je m en suis bien sorti</td>\n",
       "      <td>j ai fait preuve de main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>i did ok</td>\n",
       "      <td>je m en suis bien sortie</td>\n",
       "      <td>j ai fait preuve de main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>i did it</td>\n",
       "      <td>je l ai fait</td>\n",
       "      <td>je l ai fait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>i did it</td>\n",
       "      <td>c est moi qui l ai fait</td>\n",
       "      <td>je l ai fait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>i failed</td>\n",
       "      <td>j ai échoué</td>\n",
       "      <td>j ai échoué</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>i forgot</td>\n",
       "      <td>j ai oublié</td>\n",
       "      <td>j ai oublié</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>i get it</td>\n",
       "      <td>j ai compris</td>\n",
       "      <td>je l ai remis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>i &lt;unk&gt;</td>\n",
       "      <td>j ai fait une gaffe</td>\n",
       "      <td>je suis en train de me faire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>i got it</td>\n",
       "      <td>j ai compris</td>\n",
       "      <td>je l ai eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>i got it</td>\n",
       "      <td>j ai capté</td>\n",
       "      <td>je l ai eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>i helped</td>\n",
       "      <td>j ai aidé</td>\n",
       "      <td>j ai aidé</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tokenized Original                  Reference                   Translation\n",
       "0            good job               beau travail                   bon travail\n",
       "1            good job                      bravo                   bon travail\n",
       "2            grab tom                attrape tom                    emmène tom\n",
       "3            grab tom               attrapez tom                    emmène tom\n",
       "4            grab him                 attrape le                 lui le prenez\n",
       "5            grab him                attrapez le                 lui le prenez\n",
       "6            grab him  mettez lui la main dessus                 lui le prenez\n",
       "7            have fun             amuse toi bien              vous amusez bien\n",
       "8            have fun           amusez vous bien              vous amusez bien\n",
       "9            have fun             amuse toi bien              vous amusez bien\n",
       "10           have fun           amusez vous bien              vous amusez bien\n",
       "11           he spoke                 il a parlé                    il a parlé\n",
       "12           he spoke        il a pris la parole                    il a parlé\n",
       "13           he spoke           il s est exprimé                    il a parlé\n",
       "14           he tries                  il essaye             il reste en effet\n",
       "15           he s wet             il est mouillé                il est mouillé\n",
       "16           help tom                   aide tom           tom a besoin de tom\n",
       "17           help tom                  aidez tom           tom a besoin de tom\n",
       "18           help tom                  aidez tom           tom a besoin de tom\n",
       "19            hi guys             salut les mecs                salut les mecs\n",
       "20           how cute         comme c est mignon    de quoi que ce soit mignon\n",
       "21           how cute                trop mignon    de quoi que ce soit mignon\n",
       "22           how cute              trop mignonne    de quoi que ce soit mignon\n",
       "23           how deep          quelle profondeur              quelle déception\n",
       "24           how nice       comme elle est belle                  quelle belle\n",
       "25           how nice       comme c est chouette                  quelle belle\n",
       "26           how nice         comme c est gentil                  quelle belle\n",
       "27           how nice              c est du joli                  quelle belle\n",
       "28           how nice       comme c est agréable                  quelle belle\n",
       "29           how rude         quelle grossièreté         comment s est déroulé\n",
       "30           how wise             quelle sagesse    comment faire de ton mieux\n",
       "31           hurry up                dépêche toi                   dépêche toi\n",
       "32           hurry up                   grouille                   dépêche toi\n",
       "33           hurry up               pressez vous                   dépêche toi\n",
       "34           hurry up                       fiça                   dépêche toi\n",
       "35           hurry up                  magne toi                   dépêche toi\n",
       "36           hurry up                magnez vous                   dépêche toi\n",
       "37           i am tom                je suis tom                   je suis tom\n",
       "38           i cursed                  j ai juré                je suis désolé\n",
       "39           i did ok    je m en suis bien sorti      j ai fait preuve de main\n",
       "40           i did ok   je m en suis bien sortie      j ai fait preuve de main\n",
       "41           i did it               je l ai fait                  je l ai fait\n",
       "42           i did it    c est moi qui l ai fait                  je l ai fait\n",
       "43           i failed                j ai échoué                   j ai échoué\n",
       "44           i forgot                j ai oublié                   j ai oublié\n",
       "45           i get it               j ai compris                 je l ai remis\n",
       "46            i <unk>        j ai fait une gaffe  je suis en train de me faire\n",
       "47           i got it               j ai compris                    je l ai eu\n",
       "48           i got it                 j ai capté                    je l ai eu\n",
       "49           i helped                  j ai aidé                     j ai aidé"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations_no_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151e17a4-7d91-4356-8af6-aea691536d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37471d3-a494-47e0-b79a-a36ed47f03fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed2b233-e4a1-448c-bd42-5e95baab9892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97551c8f-f1e9-4b51-b9c5-16434c497c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d837e0e3-7a09-420c-ae86-ced75f6a44f5",
   "metadata": {},
   "source": [
    "<!-- from tensorflow.keras.utils import plot_model\n",
    "import pydot\n",
    "import graphviz \n",
    "\n",
    "# Your model definition code goes here\n",
    "\n",
    "# Plot the model and save the image \n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a67331-fc99-4e2b-814b-cca7ef0f5334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU-ENV",
   "language": "python",
   "name": "gpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
